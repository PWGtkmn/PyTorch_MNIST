{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST(kaggleバージョン)をPytorchで実行する。\n",
    "### やること\n",
    "1. データの読み込み〜Dataset化\n",
    "2. Dataloaderの定義\n",
    "3. ネットワークの定義\n",
    "4. 学習処理の定義\n",
    "5. 学習結果の可視化(損失、正答率、ラベルごとの間違い数)\n",
    "6. テスト処理の定義\n",
    "7. テスト結果の可視化（正答率、ラベルごとの間違い数）\n",
    "\n",
    "### 参考\n",
    "- Dataset, DataLoaderについて：  \n",
    "    - https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader  \n",
    "    - https://qiita.com/mathlive/items/2a512831878b8018db02\n",
    "- 学習処理の記述方法について：\n",
    "    - https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (fc4): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() ## run the Parent Class's .__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3) # (in_channnel, out_channel, kernel_size)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(400, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fc4 = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) ## J\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x)) # x.shape = (8,400)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net().double()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasetの定義\n",
    "- ここでは、データを格納しているTensorを元にDatasetクラスを作成し、Pytorch上で扱いやすくする。\n",
    "- TorchVision標準のデータセットを用いる場合、以下の流れとなるらしい。\n",
    "    - transformsによる前処理の定義(torchvision)\n",
    "        - transform：データの前処理全般を定義するもの。\n",
    "        - 今回は各pixelの値を255.0で除算する前処理を入れる。\n",
    "        - 画像なら(縦、横、チャネル)->(チャネル、縦、横)と変換する、ピクセル数を補正する、左右反転、回転させるなどの機能がある。\n",
    "    - Datasetsによる前処理&ダウンロード\n",
    "    - DataloaderによるDatasetの使用\n",
    "- 参考1：https://qiita.com/mathlive/items/2a512831878b8018db02\n",
    "- 参考2：書籍：つくりながら学ぶ！Pytorchによる発展ディープラーニング 小川雄太郎 著"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \"\"\"\n",
    "    画像に対する前処理を行うクラス。以下の機能を持つ。\n",
    "    pandas.DataFrameを入力としてTensorに変換する。\n",
    "    その後、各pixelの値を0〜1にするため、255で除算する。\n",
    "    なお、学習時と診断時での処理内容は同じであるとする。\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, df_pic):\n",
    "        \"\"\"\n",
    "        学習時と診断時での前処理は同じものとする。\n",
    "        本当は学習時のみノイズを加えたり色々する。\n",
    "        \"\"\"\n",
    "        out_label = df_pic.label\n",
    "        out_img = df_pic.iloc[:,1:].values.astype(np.uint8).reshape((1, 28, 28))\n",
    "        out_label = torch.tensor(y_train.values)\n",
    "        out_img = torch.tensor(x_train.values)\n",
    "        out_img = out_img/255.0\n",
    "        return out_img, out_label\n",
    "\n",
    "trans = ImageTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSetsの作成\n",
    "- torch.utils.data.Datasetクラスを継承して作成する。\n",
    "- メソッドには以下がある。\n",
    "    - init:コンストラクタ、クラス定義時に実行され、値の初期化などを行う。\n",
    "    - len:画像の枚数を返す。\n",
    "    - getitem:Datasetからデータを1レコード分返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDatasets(data.Dataset):\n",
    "    def __init__(self, input_filename, transform = None):\n",
    "        self.data = pd.read_csv(input_filename)\n",
    "        self.transform = trans\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_transformed = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((1, 28, 28))/255.0\n",
    "        img_label = self.data.iloc[idx, 0]\n",
    "        \n",
    "        return img_transformed, img_label\n",
    "\n",
    "ds = MnistDatasets(\"./01_input/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaderを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data.DataLoader(ds, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数と最適化手法を定義する\n",
    "損失関数には交差エントロピー損失を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## これまでに作成した関数を用いて学習を行なう。\n",
    "- パラメータの初期化\n",
    "- for epoch\n",
    "    - for ミニバッチ\n",
    "        - 順伝播\n",
    "        - 損失の計算\n",
    "        - パラメータ最適化\n",
    "            - 損失の勾配の計算\n",
    "            - パラメータの更新\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miso/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 1.499\n",
      "[1,  1000] loss: 1.499\n",
      "[1,  1500] loss: 1.494\n",
      "[1,  2000] loss: 1.498\n",
      "[1,  2500] loss: 1.491\n",
      "[1,  3000] loss: 1.495\n",
      "[1,  3500] loss: 1.498\n",
      "[1,  4000] loss: 1.493\n",
      "[1,  4500] loss: 1.493\n",
      "[1,  5000] loss: 1.501\n",
      "[2,   500] loss: 1.494\n",
      "[2,  1000] loss: 1.499\n",
      "[2,  1500] loss: 1.499\n",
      "[2,  2000] loss: 1.496\n",
      "[2,  2500] loss: 1.494\n",
      "[2,  3000] loss: 1.495\n",
      "[2,  3500] loss: 1.501\n",
      "[2,  4000] loss: 1.486\n",
      "[2,  4500] loss: 1.490\n",
      "[2,  5000] loss: 1.496\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data_jj in enumerate(dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data_jj\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.double())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 500))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルを用いた予測の実行\n",
    "- メモリにデータが乗り切るよう、100件ごとに予測値を算出する。\n",
    "- PCのメモリが足りず全データを一度に処理できなかったため。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for j in tqdm(np.arange(280)):\n",
    "    x_test_tmp = x_test.iloc[100*j:100*j+100, :]\n",
    "    x_transformed = x_test_tmp.values.astype(np.uint8).reshape((x_test_tmp.shape[0], 1, 28, 28))/255.0\n",
    "    tensor_x = torch.Tensor(x_transformed).double()\n",
    "    \n",
    "    ## 予測の実行\n",
    "    tmp_pred = net(tensor_x)\n",
    "    tmp_pred = np.argmax(tmp_pred.detach().numpy().copy(), axis=1)\n",
    "    if a==0:\n",
    "        pred = tmp_pred\n",
    "        a+=1\n",
    "    else:\n",
    "        pred = np.r_[pred, tmp_pred]\n",
    "\n",
    "## あとはpd.DataFrame(pred).to_csv()して列名をつけてSubmitする。\n",
    "## Pandasでのインデックス名の付け方を忘れた"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他：Pythonにおけるクラスの概念\n",
    "- \"class hogehoge():\" として定義する。引数には継承元の親クラスが入る。\n",
    "- アンダースコア2本で囲まれるメソッドは特殊メソッドと呼ばれる。\n",
    "    - init：インスタンスを生成する時点で実行される。\n",
    "    - call：生成したインスタンスを()つきで実行すると実行される。\n",
    "    - getitem:生成したインスタンスを[]つきで実行すると実行される。鍵カッコにはインデックスを示す整数が入る。\n",
    "- self.super().｛メソッド名｝とすると親クラスのメソッドを利用できる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
